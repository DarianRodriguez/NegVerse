{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Troubleshooting the tokenizer in polyjuice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [9360, 2551, 318, 9377, 13, 1279, 91, 11766, 5945, 91, 29, 685, 12480, 341, 60, 2332, 2551, 318, 685, 9148, 15154, 60], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "Her decision is rational. <|perturb|> [negation] Her decision is [BLANK]\n",
      "['Her', 'Ġdecision', 'Ġis', 'Ġrational', '.', 'Ġ<', '|', 'pert', 'urb', '|', '>', 'Ġ[', 'neg', 'ation', ']', 'ĠHer', 'Ġdecision', 'Ġis', 'Ġ[', 'BL', 'ANK', ']']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"uw-hai/polyjuice\"\n",
    "foundational_model=AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "input_prompt = \"Her decision is rational. <|perturb|> [negation] Her decision is [BLANK]\"\n",
    "\n",
    "# Tokenize the input_prompt\n",
    "tokens = tokenizer(input_prompt)\n",
    "token_ids = tokens[\"input_ids\"]\n",
    "\n",
    "tokens_descomp = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "\n",
    "decoded_text = tokenizer.decode(token_ids)\n",
    "\n",
    "# Extract tokens and their corresponding IDs\n",
    "#tokens = inputs.tokens()\n",
    "#token_ids = inputs.input_ids.squeeze().tolist()\n",
    "\n",
    "print(tokens)\n",
    "#print(token_ids)\n",
    "print(decoded_text)\n",
    "print(tokens_descomp)\n",
    "#print(len(token_ids ))\n",
    "#print(tokenizer.vocab_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[248], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPEFT\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcreate_blanks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_random_idxes, create_blanked_sents\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Dict, Tuple\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokens\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Doc\n",
      "\u001b[1;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from ..PEFT.create_blanks import get_random_idxes, create_blanked_sents\n",
    "from typing import List, Dict, Tuple\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "def get_random_blanked_sentences(\n",
    "    sentence: Tuple[str, Doc], \n",
    "    pre_selected_idxes: List[int]=None,\n",
    "    deps: List[str]=None,\n",
    "    is_token_only: bool=False,\n",
    "    max_blank_sent_count: int=3,\n",
    "    max_blank_block: int=1) -> List[str]:\n",
    "    \"\"\"Generate some random blanks for a given sentence\n",
    "\n",
    "    Args:\n",
    "        sentence (Tuple[str, Doc]): The sentence to be blanked,\n",
    "            either in str or SpaCy doc.\n",
    "        pre_selected_idxes (List[int], optional): \n",
    "            If set, only allow blanking a preset range of token indexes. \n",
    "            Defaults to None.\n",
    "        deps (List[str], optional): \n",
    "            If set, only select from a subset of dep tags. Defaults to None.\n",
    "        is_token_only (bool, optional):\n",
    "            blank sub-spans or just single tokens. Defaults to False.\n",
    "        max_blank_sent_count (int, optional): \n",
    "            maximum number of different blanked sentences. Defaults to 3.\n",
    "        max_blank_block (int, optional): \n",
    "            maximum number of blanks per returned sentence. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: blanked sentences\n",
    "    \"\"\"\n",
    "    indexes = get_random_idxes(\n",
    "        sentence, \n",
    "        pre_selected_idxes=pre_selected_idxes,\n",
    "        deps=deps,\n",
    "        is_token_only=is_token_only,\n",
    "        max_count=max_blank_sent_count,\n",
    "        max_blank_block=max_blank_block\n",
    "    )\n",
    "    blanked_sents = create_blanked_sents(sentence, indexes)\n",
    "    return blanked_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daria\\anaconda3\\envs\\negation\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daria\\anaconda3\\envs\\negation\\lib\\site-packages\\dill\\_dill.py:412: PicklingWarning: Cannot locate reference to <enum 'TargetType'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "c:\\Users\\daria\\anaconda3\\envs\\negation\\lib\\site-packages\\dill\\_dill.py:412: PicklingWarning: Cannot pickle <enum 'TargetType'>: __main__.TargetType has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "Map: 100%|██████████| 59/59 [00:00<00:00, 1966.39 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from enum import Enum\n",
    "\n",
    "class TargetType(Enum):\n",
    "  PAD = 0\n",
    "  CONTEXT = 1\n",
    "  CONTEXT_SPECIAL = 2\n",
    "  CONTEXT_INFILL_SEP = 3\n",
    "  INFILL = 4\n",
    "  INFILL_SPECIAL = 5\n",
    "  #INFILL_REDUNDANT = 6\n",
    "\n",
    "class TextGenerationSetup:\n",
    "\n",
    "    \"\"\"\n",
    "    Class used to setup the prompts format for training\n",
    "    \"\"\"\n",
    "    \n",
    "    PERETURB_TOK = \"<|perturb|>\"\n",
    "    BLANK_TOK = \"[BLANK]\"\n",
    "    SEP_TOK = \"[SEP]\"\n",
    "    ANSWER_TOK = \"[ANSWER]\"\n",
    "\n",
    "    def __init__(self, model_path):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.tokenizer.pad_token = None #self.tokenizer.eos_token\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_path).to(self.device)\n",
    "\n",
    "        # Add a new pad token if it doesn't exist and set it to ID 0\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "            self.tokenizer.pad_token_id = TargetType.PAD.value\n",
    "\n",
    "\n",
    "    def get_prompts(self,doc, blanked_sents, is_complete_blank=True):\n",
    "        prompts = []\n",
    "        for bt in blanked_sents:\n",
    "            tag = 'negation'\n",
    "            sep_tok = TextGenerationSetup.SEP_TOK if bt and is_complete_blank else \"\"\n",
    "            new_prompt = f\"{doc.strip()} {TextGenerationSetup.PERETURB_TOK} [{tag}] {bt.strip()}\".strip()\n",
    "            #prompts.append(new_prompt)\n",
    "            prompts.append(new_prompt.rstrip('.').strip())\n",
    "        return prompts\n",
    "\n",
    "    def get_answer_2(self,answer):\n",
    "        prompts = []\n",
    "        prompts.append(f\"{TextGenerationSetup.SEP_TOK} {answer.strip()} {TextGenerationSetup.ANSWER_TOK}\")\n",
    "        #prompts.append(answer.strip())\n",
    "        return prompts\n",
    "    \n",
    "    def get_answer(self,answers):\n",
    "        sentence = \"\"\n",
    "        initial = TextGenerationSetup.SEP_TOK\n",
    "        for answer in answers:\n",
    "            sentence += f\"{initial} {answer.strip()} {TextGenerationSetup.ANSWER_TOK}\"\n",
    "            initial = \"\"\n",
    "        return sentence\n",
    "    \n",
    "    \n",
    "    def tokenize_function(self, examples):\n",
    "\n",
    "        input_encodings = self.tokenizer(examples['input_text'], truncation=True, padding=\"max_length\", max_length=100)\n",
    "        return input_encodings\n",
    "    \n",
    "    \n",
    "    \n",
    "def process_dataframe(affixal_path, text_format ):\n",
    "\n",
    "    \"\"\"\n",
    "    Processes a DataFrame containing text data to generate a dataset suitable for text generation tasks.\n",
    "\n",
    "    This function reads a DataFrame from a pickle file, processes each row to replace specific cues with \n",
    "    a blank token, generates prompts and answers in the required format, and converts the processed data \n",
    "    into a format suitable for training a Hugging Face model.\n",
    "\n",
    "    Args:\n",
    "        affixal_path (str): Path to the pickle file containing the DataFrame with text data.\n",
    "        text_format (TextGenerationSetup): An instance of the TextGenerationSetup class used for formatting prompts and answers.\n",
    "\n",
    "    Returns:\n",
    "        Dataset: A Hugging Face Dataset object containing the processed input and target texts.\n",
    "    \"\"\"\n",
    "\n",
    "    train_data = []\n",
    "    sentence_mask = True\n",
    "\n",
    "    # Load the DataFrame from the pickle file\n",
    "    filtered_df = pd.read_pickle(affixal_path)\n",
    "\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        text = row['text']\n",
    "        text_pos = row['text_substituted']\n",
    "        cue = row['cues'].split()[0]  # Assuming 'cues' column contains space-separated cues\n",
    "\n",
    "        if sentence_mask:\n",
    "            # Replace the cue in the text with '[BLANK]'\n",
    "            text_with_blank = text.replace(cue, '[BLANK]')\n",
    "            \n",
    "            # Generate the prompt and answer\n",
    "            prompt_examples = text_format.get_prompts(text_pos, [text_with_blank]) # format the input prompts\n",
    "            answer_formatted = text_format.get_answer([cue]) # format the answer\n",
    "\n",
    "        else:\n",
    "            text_with_blank = '[BLANK]'\n",
    "            \n",
    "            # Generate the prompt and answer\n",
    "            prompt_examples = text_format.get_prompts(text_pos, [text_with_blank]) # format the input prompts\n",
    "            answer_formatted = text_format.get_answer([text]) # format the answe\n",
    "\n",
    "        # Combine the prompt and answer in the required format\n",
    "        combined_sentence = f\"{prompt_examples[0]} {answer_formatted}\"\n",
    "        train_data.append(combined_sentence)\n",
    "\n",
    "    # Convert to a suitable format for Hugging Face Dataset\n",
    "    train_dataset= pd.DataFrame(train_data, columns=[\"input_text\"]) #columns=[\"input_text\", \"target_text\"]\n",
    "    train_dataset = Dataset.from_pandas(train_dataset)\n",
    "    \n",
    "    return train_dataset\n",
    "\n",
    "# Setup the model\n",
    "model_path = \"uw-hai/polyjuice\"  \n",
    "text_format = TextGenerationSetup(model_path)\n",
    "\n",
    "# Load affixal negations dataset in the right format for training\n",
    "affixal_df = '../data/affixal/filtered_df.pkl' # Specify the path to the pickle file\n",
    "train_dataset = process_dataframe(affixal_df,text_format)\n",
    "tokenized_datasets = train_dataset.map(text_format.tokenize_function) # batched=True, remove_columns=[\"input_text\", \"target_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'too much of it feels focused and underdeveloped . <|perturb|> [negation] [BLANK] [SEP] too much of it feels unfocused and underdeveloped . [ANSWER]'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['input_text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_text'],\n",
       "    num_rows: 59\n",
       "})"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['input_text'][50]\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating other datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negated</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not all people have had the opportunities you have had.</td>\n",
       "      <td>Every person has had the opportunities you have had.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not all people have had the opportunities you have had.</td>\n",
       "      <td>All people have had the opportunities you have had.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No one has had the opportunities you have had.</td>\n",
       "      <td>All people have had the opportunities you have had.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw nothing at all.</td>\n",
       "      <td>I saw something.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not often do we see her lose her cool like that.</td>\n",
       "      <td>We frequently see her lose her cool like that.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   negated  \\\n",
       "0  Not all people have had the opportunities you have had.   \n",
       "1  Not all people have had the opportunities you have had.   \n",
       "2           No one has had the opportunities you have had.   \n",
       "3                                    I saw nothing at all.   \n",
       "4         Not often do we see her lose her cool like that.   \n",
       "\n",
       "                                               original  \n",
       "0  Every person has had the opportunities you have had.  \n",
       "1   All people have had the opportunities you have had.  \n",
       "2   All people have had the opportunities you have had.  \n",
       "3                                      I saw something.  \n",
       "4        We frequently see her lose her cool like that.  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/non_verbal/sentence_negated_modified.txt' \n",
    "\n",
    "# Load the data into a DataFrame\n",
    "df_dataset = pd.read_csv(data_path, delimiter='\\t')\n",
    "\n",
    "df_dataset.head()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not all people have had the opportunities you have had.\n",
      "negated     Not all people have had the opportunities you have had.\n",
      "original       Every person has had the opportunities you have had.\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "first_row = df_dataset.loc[0]\n",
    "print(first_row['negated'])\n",
    "print(first_row)\n",
    "\n",
    "negated = first_row['negated']\n",
    "original = first_row['original']\n",
    "\n",
    "####### Function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negated</th>\n",
       "      <th>original</th>\n",
       "      <th>mask</th>\n",
       "      <th>masked_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not all people have had the opportunities you have had.</td>\n",
       "      <td>Every person has had the opportunities you have had.</td>\n",
       "      <td>[BLANK] had the opportunities you have had.</td>\n",
       "      <td>[Not all people have]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not all people have had the opportunities you have had.</td>\n",
       "      <td>All people have had the opportunities you have had.</td>\n",
       "      <td>[BLANK] people have had the opportunities you have had.</td>\n",
       "      <td>[Not all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No one has had the opportunities you have had.</td>\n",
       "      <td>All people have had the opportunities you have had.</td>\n",
       "      <td>[BLANK] had the opportunities you have had.</td>\n",
       "      <td>[No one has]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw nothing at all.</td>\n",
       "      <td>I saw something.</td>\n",
       "      <td>I saw [BLANK]</td>\n",
       "      <td>[nothing at all.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not often do we see her lose her cool like that.</td>\n",
       "      <td>We frequently see her lose her cool like that.</td>\n",
       "      <td>[BLANK] see her lose her cool like that.</td>\n",
       "      <td>[Not often do we]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   negated  \\\n",
       "0  Not all people have had the opportunities you have had.   \n",
       "1  Not all people have had the opportunities you have had.   \n",
       "2           No one has had the opportunities you have had.   \n",
       "3                                    I saw nothing at all.   \n",
       "4         Not often do we see her lose her cool like that.   \n",
       "\n",
       "                                               original  \\\n",
       "0  Every person has had the opportunities you have had.   \n",
       "1   All people have had the opportunities you have had.   \n",
       "2   All people have had the opportunities you have had.   \n",
       "3                                      I saw something.   \n",
       "4        We frequently see her lose her cool like that.   \n",
       "\n",
       "                                                      mask  \\\n",
       "0              [BLANK] had the opportunities you have had.   \n",
       "1  [BLANK] people have had the opportunities you have had.   \n",
       "2              [BLANK] had the opportunities you have had.   \n",
       "3                                            I saw [BLANK]   \n",
       "4                 [BLANK] see her lose her cool like that.   \n",
       "\n",
       "             masked_info  \n",
       "0  [Not all people have]  \n",
       "1              [Not all]  \n",
       "2           [No one has]  \n",
       "3      [nothing at all.]  \n",
       "4      [Not often do we]  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Create DataFrame\n",
    "df = df_dataset\n",
    "\n",
    "def mask_differences(negated, original):\n",
    "\n",
    "    # Tokenize sentences\n",
    "    negated_tokens = np.array(negated.split())\n",
    "    original_tokens = np.array(original.split())\n",
    "    \n",
    "    # Use SequenceMatcher to find matching blocks\n",
    "    matcher = SequenceMatcher(None, negated_tokens, original_tokens)\n",
    "    \n",
    "    # Initialize mask tokens and list to capture masked segments\n",
    "    mask_tokens = []\n",
    "    masked_info = []\n",
    "    prev_end = 0\n",
    "    \n",
    "    for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
    "        if tag == 'replace' or tag == 'delete':\n",
    "            if prev_end < i1:\n",
    "                # Add [BLANK] for non-matching segments\n",
    "                mask_tokens.extend(['[BLANK]'] * (i1 - prev_end))\n",
    "                # Capture the masked segment\n",
    "                masked_info.append(' '.join(negated_tokens[prev_end:i1]))\n",
    "            else:\n",
    "                # Consolidate contiguous [BLANK] tokens\n",
    "                if mask_tokens and mask_tokens[-1] == '[BLANK]':\n",
    "                    mask_tokens = mask_tokens[:-1]\n",
    "                mask_tokens.append('[BLANK]')\n",
    "                masked_info.append(' '.join(negated_tokens[i1:i2]))\n",
    "        elif tag == 'insert':\n",
    "            # Skip inserted parts as they are not in negated_tokens\n",
    "            pass\n",
    "        else:  # 'equal'\n",
    "            # Add matching tokens to the mask\n",
    "            mask_tokens.extend(negated_tokens[i1:i2])\n",
    "        \n",
    "        prev_end = i2\n",
    "    \n",
    "    # Handle trailing [BLANK] segments\n",
    "    if prev_end < len(negated_tokens):\n",
    "        mask_tokens.extend(['[BLANK]'] * (len(negated_tokens) - prev_end))\n",
    "        masked_info.append(' '.join(negated_tokens[prev_end:]))\n",
    "    \n",
    "    # Consolidate contiguous [BLANK] segments into a single [BLANK]\n",
    "    mask_array = []\n",
    "    in_blank_segment = False\n",
    "    for token in mask_tokens:\n",
    "        if token == '[BLANK]':\n",
    "            if not in_blank_segment:\n",
    "                mask_array.append('[BLANK]')\n",
    "                in_blank_segment = True\n",
    "        else:\n",
    "            mask_array.append(token)\n",
    "            in_blank_segment = False\n",
    "    \n",
    "    # Convert mask tokens to a single string\n",
    "    masked_sentence = ' '.join(mask_array)\n",
    "    \n",
    "    return masked_sentence, masked_info\n",
    "\n",
    "# Apply function to the DataFrame\n",
    "df[['mask', 'masked_info']] = df.apply(lambda row: pd.Series(mask_differences(row['negated'], row['original'])), axis=1)\n",
    "\n",
    "# Convert 'masked_info' column to lists of masked segments\n",
    "df['masked_info'] = df['masked_info'].apply(lambda x: [seg for seg in x if seg.strip()])\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEP] Not unreasonably, [ANSWER] asked [ANSWER]\n"
     ]
    }
   ],
   "source": [
    "SEP_TOK = \"[SEP]\"\n",
    "ANSWER_TOK = \"[ANSWER]\"\n",
    "\n",
    "def get_answer(answers):\n",
    "    sentence = \"\"\n",
    "    initial = SEP_TOK\n",
    "    for answer in answers:\n",
    "        sentence += f\"{initial} {answer.strip()} {ANSWER_TOK}\"\n",
    "        initial = \"\"\n",
    "    return sentence\n",
    "\n",
    "exp = df['masked_info'][45]\n",
    "\n",
    "xx = get_answer(exp)\n",
    "print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daria\\anaconda3\\envs\\negation\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daria\\anaconda3\\envs\\negation\\lib\\site-packages\\datasets\\table.py:1395: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "c:\\Users\\daria\\anaconda3\\envs\\negation\\lib\\site-packages\\datasets\\table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "c:\\Users\\daria\\anaconda3\\envs\\negation\\lib\\site-packages\\dill\\_dill.py:412: PicklingWarning: Cannot locate reference to <enum 'TargetType'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "c:\\Users\\daria\\anaconda3\\envs\\negation\\lib\\site-packages\\dill\\_dill.py:412: PicklingWarning: Cannot pickle <enum 'TargetType'>: __main__.TargetType has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "Map: 100%|██████████| 160/160 [00:00<00:00, 2285.77 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "SEP_TOK = \"[SEP]\"\n",
    "ANSWER_TOK = \"[ANSWER]\"\n",
    "\n",
    "def get_answer2(answers):\n",
    "    sentence = \"\"\n",
    "    initial = SEP_TOK\n",
    "    for answer in answers:\n",
    "        sentence += f\"{initial} {answer.strip()} {ANSWER_TOK}\"\n",
    "        initial = \"\"\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def get_answer(answers):\n",
    "    sentence = \"\"\n",
    "    for answer in answers:\n",
    "        sentence += f\"{SEP_TOK} {answer.strip()} {ANSWER_TOK} \"\n",
    "    return sentence.strip()\n",
    "\n",
    "\n",
    "def process_dataframe_general(filtered_df,text_format):\n",
    "\n",
    "        \"\"\"\n",
    "        Processes a DataFrame containing text data to generate a dataset suitable for text generation tasks.\n",
    "\n",
    "        This function reads a DataFrame from a pickle file, processes each row to replace specific cues with \n",
    "        a blank token, generates prompts and answers in the required format, and converts the processed data \n",
    "        into a format suitable for training a Hugging Face model.\n",
    "\n",
    "        Args:\n",
    "            affixal_path (str): Path to the pickle file containing the DataFrame with text data.\n",
    "            text_format (TextGenerationSetup): An instance of the TextGenerationSetup class used for formatting prompts and answers.\n",
    "\n",
    "        Returns:\n",
    "            Dataset: A Hugging Face Dataset object containing the processed input and target texts.\n",
    "        \"\"\"\n",
    "\n",
    "        train_data = []\n",
    "        sentence_mask = True\n",
    "\n",
    "        for _, row in filtered_df.iterrows():\n",
    "            negated = row['negated']\n",
    "            original = row['original']\n",
    "            \n",
    "            \n",
    "            if sentence_mask :\n",
    "                # Replace the cue in the text with '[BLANK]'\n",
    "                text_with_blank = row['mask']\n",
    "                answer = row['masked_info']\n",
    "            else:\n",
    "                text_with_blank = '[BLANK]'\n",
    "                answer = [negated]\n",
    "            \n",
    "            # Generate the prompt and answer\n",
    "            prompt_examples = text_format.get_prompts(original, [text_with_blank]) # format the input prompts\n",
    "            answer_formatted = get_answer2(answer) # format the answer\n",
    "            \n",
    "            # Combine the prompt and answer in the required format\n",
    "            combined_sentence = f\"{prompt_examples[0]} {answer_formatted}\"\n",
    "            train_data.append(combined_sentence)\n",
    "\n",
    "        # Convert to a suitable format for Hugging Face Dataset\n",
    "        train_dataset= pd.DataFrame(train_data, columns=[\"input_text\"]) #columns=[\"input_text\", \"target_text\"]\n",
    "        train_dataset = Dataset.from_pandas(train_dataset)\n",
    "        \n",
    "        return train_dataset\n",
    "\n",
    "# Setup the model\n",
    "model_path = \"uw-hai/polyjuice\"  \n",
    "text_format = TextGenerationSetup(model_path)\n",
    "\n",
    "train_dataset_2 = process_dataframe_general(df,text_format)\n",
    "unified_dataset = concatenate_datasets([train_dataset_2, train_dataset])\n",
    "tokenized_datasets_2 = unified_dataset.map(text_format.tokenize_function) # batched=True, remove_columns=[\"input_text\", \"target_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "unified_dataset = concatenate_datasets([train_dataset_2, train_dataset])\n",
    "\n",
    "# Output the unified dataset\n",
    "#print(unified_dataset)\n",
    "\n",
    "#train_dataset_2 #['input_text'][45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[225], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#train_dataset['input_text'][45]\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#unified_dataset['input_text'][28]\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m59\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#train_dataset['input_text'][45]\n",
    "#unified_dataset['input_text'][28]\n",
    "train_dataset['input_text'][59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daria\\anaconda3\\envs\\negation\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daria\\anaconda3\\envs\\negation\\lib\\site-packages\\dill\\_dill.py:412: PicklingWarning: Cannot locate reference to <enum 'TargetType'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "c:\\Users\\daria\\anaconda3\\envs\\negation\\lib\\site-packages\\dill\\_dill.py:412: PicklingWarning: Cannot pickle <enum 'TargetType'>: __main__.TargetType has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "Map: 100%|██████████| 160/160 [00:00<00:00, 993.64 examples/s] \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "from datasets import Dataset\n",
    "from enum import Enum\n",
    "\n",
    "class Special_tokens():\n",
    "    PERETURB_TOK = \"<|perturb|>\"\n",
    "    BLANK_TOK = \"[BLANK]\"\n",
    "    SEP_TOK = \"[SEP]\"\n",
    "    ANSWER_TOK = \"[ANSWER]\"\n",
    "    NEG_TOK = \"[negation]\"\n",
    "\n",
    "    @classmethod\n",
    "    def initialize_token_ids(cls, tokenizer):\n",
    "        cls.PERETURB_TOK_ID = [tokenizer(cls.PERETURB_TOK)['input_ids'], tokenizer(\" \" + cls.PERETURB_TOK)['input_ids']]\n",
    "        cls.BLANK_TOK_ID = [tokenizer(cls.BLANK_TOK)['input_ids'], tokenizer(\" \" + cls.BLANK_TOK)['input_ids']]\n",
    "        cls.SEP_TOK_ID = [tokenizer(cls.SEP_TOK)['input_ids'], tokenizer(\" \" + cls.SEP_TOK)['input_ids']]\n",
    "        cls.ANSWER_TOK_ID = [tokenizer(cls.ANSWER_TOK)['input_ids'], tokenizer(\" \" + cls.ANSWER_TOK)['input_ids']]\n",
    "        cls.NEG_TOK_ID = [tokenizer(cls.NEG_TOK)['input_ids'], tokenizer(\" \" + cls.NEG_TOK)['input_ids']]\n",
    "\n",
    "class TargetType(Enum):\n",
    "    PAD = 0\n",
    "    CONTEXT = 1\n",
    "    CONTEXT_SPECIAL = 2\n",
    "    CONTEXT_INFILL_SEP = 3\n",
    "    INFILL = 4\n",
    "    INFILL_SPECIAL = 5\n",
    "\n",
    "def setup_model(model_path):\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "  tokenizer.pad_token = None #self.tokenizer.eos_token\n",
    "  model = AutoModelForCausalLM.from_pretrained(model_path) #.to(device)\n",
    "\n",
    "  # Add a new pad token if it doesn't exist and set it to ID 0\n",
    "  if tokenizer.pad_token is None:\n",
    "      tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "      tokenizer.pad_token_id = TargetType.PAD.value\n",
    "\n",
    "  return device,tokenizer, model\n",
    "\n",
    "class Trainer_preprocess:\n",
    "    def __init__(self, tokenizer, batch_size = 8):\n",
    "        self.tokenizer = tokenizer\n",
    "        #self.train_dataset = train_dataset\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def tokenized_special_tokens(self):\n",
    "        # Call the function to initialize token IDs\n",
    "        Special_tokens.initialize_token_ids(self.tokenizer)\n",
    "\n",
    "    def extract_token(self, token_list, special_tok_ids, target_value):\n",
    "        # Mask the position of special tokens\n",
    "            token_len = len(special_tok_ids[0])\n",
    "            index = 0\n",
    "\n",
    "            if any(token_list[:token_len] == tok_id for tok_id in special_tok_ids):\n",
    "                label = [target_value] * token_len\n",
    "                index = token_len  # Skip the next three tokens as they are part of the negation marker\n",
    "            else:\n",
    "                label = None\n",
    "\n",
    "            return index, label\n",
    "    \n",
    "    \n",
    "    def align_labels(self, input_data):\n",
    "        tokens = input_data['input_ids']\n",
    "\n",
    "        # Initialize the list of labels\n",
    "        labels = [TargetType.PAD.value] * len(tokens)\n",
    "\n",
    "        special_list = [\n",
    "            Special_tokens.PERETURB_TOK_ID, \n",
    "            Special_tokens.BLANK_TOK_ID, \n",
    "            Special_tokens.NEG_TOK_ID,\n",
    "            Special_tokens.SEP_TOK_ID,\n",
    "            Special_tokens.ANSWER_TOK_ID\n",
    "        ]\n",
    "        target_list = [\n",
    "            TargetType.CONTEXT_SPECIAL.value,\n",
    "            TargetType.CONTEXT_SPECIAL.value,\n",
    "            TargetType.CONTEXT_SPECIAL.value,\n",
    "            TargetType.CONTEXT_INFILL_SEP.value,\n",
    "            TargetType.INFILL_SPECIAL.value\n",
    "        ]\n",
    "\n",
    "        # Assign labels\n",
    "        i = 0\n",
    "        while i < len(tokens) and tokens[i] != TargetType.PAD.value:\n",
    "            token_processed = False\n",
    "            for special_token, target_type in zip(special_list, target_list):\n",
    "                step, label = self.extract_token(tokens[i:], special_token, target_type)\n",
    "                if step != 0 and label is not None:\n",
    "                    token_processed = True\n",
    "                    break\n",
    "\n",
    "            if token_processed:\n",
    "                labels[i:i + step] = label\n",
    "                i += step\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "        # Modify the labels list to add context and answer mask\n",
    "        labels = [\n",
    "            1 if x == TargetType.PAD.value and 3 in labels[i:] else  # All zeros before 2 should be changed to 1\n",
    "            4 if x == TargetType.PAD.value and 3 in labels[:i] and 5 in labels[i:] else  # All zero values between 3 and 5 should be changed to 4\n",
    "            x\n",
    "            for i, x in enumerate(labels)\n",
    "        ]\n",
    "\n",
    "        return {'aligned_labels': labels}\n",
    "    \n",
    "    def create_data_loader(self,tokenized_dataset):\n",
    "        # Call tokenized_special_tokens to initialize token IDs\n",
    "        self.tokenized_special_tokens()\n",
    "\n",
    "        # Apply align_labels function to the dataset\n",
    "        train_dataset = tokenized_dataset.map(self.align_labels)\n",
    "\n",
    "        # Extract input_ids and aligned_labels\n",
    "        input_ids = np.array(train_dataset['input_ids'])\n",
    "        aligned_labels = np.array(train_dataset['aligned_labels'])\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        input_ids_tensor = torch.from_numpy(input_ids.astype(np.int64))\n",
    "        aligned_labels_tensor = torch.from_numpy(aligned_labels.astype(np.int64))\n",
    "\n",
    "        # Create TensorDataset\n",
    "        train_data = TensorDataset(input_ids_tensor, aligned_labels_tensor)\n",
    "\n",
    "        # Create RandomSampler for training\n",
    "        train_sampler = RandomSampler(train_data)\n",
    "\n",
    "        # Create DataLoader\n",
    "        train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=self.batch_size, drop_last=True)\n",
    "\n",
    "        return train_dataloader, train_data, train_dataset\n",
    "\n",
    "# Initialize parameters\n",
    "\n",
    "# Load model setup\n",
    "device,tokenizer, model = setup_model(model_path)\n",
    "batch_size = 8\n",
    "\n",
    "# Prepare the dataset for training\n",
    "prep_train = Trainer_preprocess(tokenizer, batch_size)\n",
    "train_dataloader, train_data, tok_data = prep_train.create_data_loader(tokenized_datasets_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[BLANK]'"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data[45]\n",
    "Special_tokens.BLANK_TOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3118, 41181, 1346, 11, 339, 750, 407, 1265, 329, 6074, 287, 5963, 13, 1279, 91, 11766, 5945, 91, 29, 685, 12480, 341, 60, 685, 9148, 15154, 60, 339, 685, 9148, 15154, 60, 329, 6074, 287, 5963, 685, 5188, 47, 60, 1892, 14880, 888, 1346, 11, 685, 15037, 45532, 60, 1965, 685, 15037, 45532, 60, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['Un', 'reason', 'ably', ',', 'Ġhe', 'Ġdid', 'Ġnot', 'Ġask', 'Ġfor', 'Ġpayment', 'Ġin', 'Ġadvance', '.', 'Ġ<', '|', 'pert', 'urb', '|', '>', 'Ġ[', 'neg', 'ation', ']', 'Ġ[', 'BL', 'ANK', ']', 'Ġhe', 'Ġ[', 'BL', 'ANK', ']', 'Ġfor', 'Ġpayment', 'Ġin', 'Ġadvance', 'Ġ[', 'SE', 'P', ']', 'ĠNot', 'Ġunre', 'ason', 'ably', ',', 'Ġ[', 'ANS', 'WER', ']', 'Ġasked', 'Ġ[', 'ANS', 'WER', ']', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!']\n",
      "Unreasonably, he did not ask for payment in advance. <|perturb|> [negation] [BLANK] he [BLANK] for payment in advance [SEP] Not unreasonably, [ANSWER] asked [ANSWER]!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "token_ids = tokenized_datasets_2[45]['input_ids']\n",
    "decoded_text = text_format.tokenizer.decode(token_ids)\n",
    "tokens_descomp = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "print(token_ids)\n",
    "print(tokens_descomp)\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n",
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n",
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n",
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n",
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n",
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n",
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n",
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n",
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n",
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n",
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n",
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n",
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n",
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n",
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n",
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n",
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n",
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n",
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n",
      "Batch shape - Input IDs: torch.Size([8, 100]) Aligned Labels: torch.Size([8, 100])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    input_ids_batch, aligned_labels_batch = batch\n",
    "    # Accessing the shape of tensors inside the batch\n",
    "    print(\"Batch shape - Input IDs:\", input_ids_batch.shape, \"Aligned Labels:\", aligned_labels_batch.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data[0]\n",
    "#tok_data[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,072 || all params: 124,442,880 || trainable%: 0.0024686024624309562\n",
      "None\n",
      "Epoch 0 , Train loss: 1.8651\n",
      "Epoch 1 , Train loss: 1.9174\n",
      "Epoch 2 , Train loss: 1.9332\n",
      "Epoch 3 , Train loss: 1.8919\n",
      "Epoch 4 , Train loss: 1.7805\n",
      "Epoch 5 , Train loss: 1.8695\n",
      "Epoch 6 , Train loss: 1.9227\n",
      "Epoch 7 , Train loss: 1.9362\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW, CONFIG_NAME, WEIGHTS_NAME\n",
    "from peft import PromptTuningConfig, TaskType, PromptTuningInit, get_peft_model,PeftModel\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def set_random_seed(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def tts_to_labels(inputs, tts, label_tts):\n",
    "  # Extract only the relevant token ids\n",
    "  selector = torch.zeros_like(inputs, dtype=torch.bool)\n",
    "  for tt in label_tts:\n",
    "    selector |= tts == tt.value\n",
    "  return torch.where(\n",
    "      selector,\n",
    "      inputs,\n",
    "      torch.full_like(inputs, -1))\n",
    "\n",
    "def plot_training_loss(train_history):\n",
    "    \"\"\"\n",
    "    Plot the training loss over epochs.\n",
    "    \n",
    "    Args:\n",
    "        train_history (list): List of training loss values for each epoch.\n",
    "        train_num_epochs (int): Number of epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    train_num_epochs = len(train_history)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    epochs = np.arange(train_num_epochs)  # Array of epoch indices\n",
    "    plt.plot(epochs, train_history, marker='o', linestyle='-', color='b')\n",
    "    plt.title('Training Loss per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xticks(ticks=epochs)  # Set x-axis ticks to integer values\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def train_fn(train_dataloader,model,device,optimizer,num_virtual_tokens): \n",
    "\n",
    "  total_loss = 0\n",
    "  train_context = False\n",
    "\n",
    "  for batch in train_dataloader:\n",
    "\n",
    "    inputs, tts = tuple(t.to(device) for t in batch)\n",
    "    labels_context = tts_to_labels(inputs, tts, [TargetType.CONTEXT])\n",
    "    labels_infill = tts_to_labels(inputs, tts, [TargetType.INFILL, TargetType.INFILL_SPECIAL])\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    logits =  outputs.logits\n",
    "    #logits_relevant = logits[:, :-1].contiguous().view(-1, logits.shape[-1])\n",
    "    logits_relevant = logits[:, num_virtual_tokens:-1].contiguous().view(-1, logits.shape[-1])\n",
    "    #logits_relevant = logits[:, num_virtual_tokens:].contiguous().view(-1, logits.shape[-1])\n",
    "\n",
    "    #print(\"logits\", logits_relevant.shape)\n",
    "    #x = labels_context[:, :].contiguous().view(-1)\n",
    "    #print(x.shape)\n",
    "    #print(\"labels\", labels_infill.shape)\n",
    "\n",
    "    loss_context = F.cross_entropy(\n",
    "        logits_relevant,\n",
    "        labels_context[:, 1:].contiguous().view(-1),\n",
    "        ignore_index=-1)\n",
    "    \n",
    "    loss_infill = F.cross_entropy(\n",
    "        logits_relevant,\n",
    "        labels_infill[:, 1:].contiguous().view(-1),\n",
    "        ignore_index=-1)\n",
    "\n",
    "    loss_context_item = loss_context.item()\n",
    "    loss_infill_item = loss_infill.item()\n",
    "\n",
    "    loss = loss_infill\n",
    "\n",
    "    if train_context:\n",
    "      loss += loss_context\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "\n",
    "  avg_train_loss = total_loss / len(train_dataloader)\n",
    "  return avg_train_loss\n",
    "\n",
    "\n",
    "def train_engine(train_loader,train_num_epochs,model, device,num_virtual_tokens):\n",
    "\n",
    "  model.train()\n",
    "  train_history = []\n",
    "\n",
    "  train_learning_rate = 5e-5\n",
    "  train_adam_epsilon = 1e-8\n",
    "\n",
    "  optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=train_learning_rate,\n",
    "    eps=train_adam_epsilon)\n",
    "\n",
    "  for i in range(train_num_epochs):\n",
    "    train_loss = train_fn(train_loader, model, device,optimizer,num_virtual_tokens)\n",
    "    train_history.append(train_loss)\n",
    "    print(f\"Epoch {i} , Train loss: {train_loss:.4f}\")\n",
    "\n",
    "  # Call the plotting function\n",
    "  plot_training_loss(train_history)\n",
    "\n",
    "\n",
    "  return model\n",
    "\n",
    "def create_peft_model(num_virtual_tokens, model_path = \"uw-hai/polyjuice\"):\n",
    "  \n",
    "  foundational_model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "  # Define prompt tuning configuration\n",
    "  peft_config = PromptTuningConfig(\n",
    "      task_type=TaskType.CAUSAL_LM, # This type indicates the model will generate text.\n",
    "      prompt_tuning_init=PromptTuningInit.RANDOM,  # The added virtual tokens are initialized with random numbers\n",
    "      num_virtual_tokens=num_virtual_tokens, # Number of virtual tokens to be added and trained.\n",
    "      tokenizer_name_or_path=model_path # The pre-trained model.\n",
    "  )\n",
    "\n",
    "  peft_model = get_peft_model(foundational_model, peft_config)\n",
    "  print(peft_model.print_trainable_parameters())\n",
    "\n",
    "  return peft_model\n",
    "\n",
    "def create_model_directories(base_dir, output_dir_name):\n",
    "    \"\"\"\n",
    "    Creates the base and output directories for storing models if they do not exist.\n",
    "    \n",
    "    Parameters:\n",
    "    base_dir (str): The base working directory.\n",
    "    output_dir_name (str): The name of the output directory.\n",
    "    \n",
    "    Returns:\n",
    "    str: The path to the output directory.\n",
    "    \"\"\"\n",
    "    # Create the name of the output directory\n",
    "    output_directory = os.path.join(base_dir, output_dir_name)\n",
    "    \n",
    "    # Create the base directory if it does not exist\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.mkdir(base_dir)\n",
    "    \n",
    "    # Create the output directory if it does not exist\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.mkdir(output_directory)\n",
    "    \n",
    "    return output_directory\n",
    "\n",
    "\n",
    "# Create directory to save the trained model\n",
    "working_dir=\"./\"\n",
    "output_dir_name=\"peft_outputs\"\n",
    "output_directory = create_model_directories(working_dir, output_dir_name)\n",
    "\n",
    "\n",
    "# Parameters\n",
    "seed = 40\n",
    "EPOCHS = 8\n",
    "num_virtual_tokens = 4\n",
    "\n",
    "set_random_seed(seed)\n",
    "\n",
    "# Create new model for soft tuning \n",
    "model_peft = create_peft_model(num_virtual_tokens)\n",
    "model_peft.to(device)\n",
    "\n",
    "trained_model = train_engine(train_dataloader,EPOCHS, model_peft, device,num_virtual_tokens)\n",
    "\n",
    "# Save the trained model\n",
    "trained_model.save_pretrained(output_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelinference:\n",
    "    def __init__(self, model, tokenizer, output_dir_name):\n",
    "        self.output_directory = output_dir_name\n",
    "        self.foundational_model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "\n",
    "    #this function returns the outputs from the model received, and inputs.\n",
    "    def get_outputs(self,model,inputs,do_sample=True,num_beams=None,num_return_sequences = 3):\n",
    "        \"\"\"\n",
    "        Generates multiple sequences of text using the provided model and inputs.\n",
    "\n",
    "        Args:\n",
    "            model: The model used for generation.\n",
    "            inputs (dict): Input tensors including 'input_ids' and 'attention_mask'.\n",
    "            do_sample (bool, optional): Whether to use sampling during generation (default: True).\n",
    "            num_beams (int, optional): Number of beams for beam search. Overrides `do_sample`.\n",
    "            num_return_sequences (int, optional): Number of sequences to generate per input (default: 3).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Tensor containing generated sequences.\n",
    "        \"\"\"\n",
    "\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=30,\n",
    "            early_stopping=False, #if num_beams is None else True, #The model can stop before reach the max_length\n",
    "            temperature= 1,\n",
    "            num_beams=1 if num_beams is None else num_beams,\n",
    "            do_sample=num_beams is None and do_sample,\n",
    "            num_return_sequences=num_return_sequences,\n",
    "        )\n",
    "        return outputs\n",
    "    \n",
    "    def inference (self,input_prompt,num_return_sequences = 3, num_beams = 5 ):\n",
    "        \"\"\"\n",
    "        Generate text sequences based on an input prompt using a pretrained model saved in the directory.\n",
    "\n",
    "        Args:\n",
    "            input_prompt (str): The input prompt text to generate sequences from.\n",
    "\n",
    "        Returns:\n",
    "            list: List of generated text sequences as decoded by the tokenizer, without special tokens.\n",
    "        \"\"\"\n",
    "\n",
    "        loaded_model_prompt = PeftModel.from_pretrained(self.foundational_model,\n",
    "                                         self.output_directory,\n",
    "                                         device_map='auto',\n",
    "                                         is_trainable=False)\n",
    "        \n",
    "        input_prompt_tok = self.tokenizer(input_prompt, return_tensors=\"pt\")\n",
    "        loaded_model_prompt_outputs = self.get_outputs(loaded_model_prompt, input_prompt_tok,num_beams = num_beams,num_return_sequences = num_return_sequences)\n",
    "        result = self.tokenizer.batch_decode(loaded_model_prompt_outputs, skip_special_tokens=True)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./peft_outputs\n"
     ]
    }
   ],
   "source": [
    "print(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Her decision is rational love. <|perturb|> [negation] Her decision is [BLANK] love. [SEP] not', 'Her decision is rational love. <|perturb|> [negation] Her decision is [BLANK] love. \" [SEP]', 'Her decision is rational love. <|perturb|> [negation] Her decision is [BLANK] love. [SEP] n']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_prompt = \"Her decision is rational love. <|perturb|> [negation] Her decision is [BLANK] love\"\n",
    "\n",
    "# Define your foundational model, tokenizer, and tokenized datasets\n",
    "foundational_model = model\n",
    "model_name = \"uw-hai/polyjuice\"\n",
    "\n",
    "# Initialize the ModelTrainer class\n",
    "inf_class =  Modelinference(foundational_model, tokenizer, output_directory)\n",
    "\n",
    "sequence = inf_class.inference (input_prompt)\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1169,  3807,   705,    82,  5365,  2829,  7110,   290,  8253, 18016,\n",
      "          711,   880,   351,   262,  1527,   540,  3350,   764,  1279,    91,\n",
      "        11766,  5945,    91,    29,   685, 12480,   341,    60,   262,  3807,\n",
      "          705,    82,  5365,  2829,  7110,   290,   685,  9148, 15154,    60,\n",
      "        18016,   711,   880,   351,   262,  1527,   540,  3350,   685,  5188,\n",
      "           47,    60,  8820,   489,  3474,   685, 15037, 45532,    60,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        3, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])\n",
    "print(tts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49123, 329, 257, 2495, 15497, 11681, 1998, 764, 1279, 91, 11766, 5945, 91, 29, 685, 12480, 341, 60, 1838, 329, 257, 2495, 685, 9148, 15154, 60, 11681, 1998, 685, 5188, 47, 60, 22029, 685, 15037, 45532, 60, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['makes', 'Ġfor', 'Ġa', 'Ġpretty', 'Ġpleasant', 'Ġviewing', 'Ġexperience', 'Ġ.', 'Ġ<', '|', 'pert', 'urb', '|', '>', 'Ġ[', 'neg', 'ation', ']', 'Ġmakes', 'Ġfor', 'Ġa', 'Ġpretty', 'Ġ[', 'BL', 'ANK', ']', 'Ġviewing', 'Ġexperience', 'Ġ[', 'SE', 'P', ']', 'Ġunpleasant', 'Ġ[', 'ANS', 'WER', ']', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!', '!']\n",
      "makes for a pretty pleasant viewing experience. <|perturb|> [negation] makes for a pretty [BLANK] viewing experience [SEP] unpleasant [ANSWER]!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "#tokenized_datasets[0]\n",
    "token_ids = tokenized_datasets[8]['input_ids']\n",
    "decoded_text = text_format.tokenizer.decode(token_ids)\n",
    "tokens_descomp = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "print(token_ids)\n",
    "print(tokens_descomp)\n",
    "print(decoded_text)\n",
    "\n",
    "#[27, 91, 11766, 5945, 91, 29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 124439808\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model_path = \"uw-hai/polyjuice\"  \n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "count_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Print the number of trainable parameters\n",
    "print(f'Number of trainable parameters: {count_trainable_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "pickle_file_path = \"../data/verbal/verbal_df.pkl\"\n",
    "\n",
    "# Load the pickle file\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Print the loaded pickle file data (optional, for verification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original_Sentence        Deng Yaping of China is the first female recorded at the inaugural Women ' s World Cup in 1996\n",
      "Negated_Sentence     Deng Yaping of China is not the first female recorded at the inaugural Women ' s World Cup in 1996\n",
      "Name: 4, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "print(data.iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "pickle_file_path = \"../data/verbal/verbal_df.pkl\"\n",
    "\n",
    "# Load the pickle file\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    data2 = pickle.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "negation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
